name: Run Crawler Every 15 Minutes

env:
  DISCORD_WEBHOOK: ${{ secrets.DISCORD_WEBHOOK }}

on:
  schedule:
    - cron: "*/15 * * * *"  # 每 15 分鐘執行一次
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run crawler script
        run: python crawler.py

      - name: Commit and Push updated sent_links.json (if changed)
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@github.com"
          
          git add -f sent_links.json

          if ! git diff --cached --quiet; then
            git commit -m "Update sent_links.json [skip ci]"
            git push origin HEAD:main
          else
            echo "No changes to sent_links.json. Skipping push."
